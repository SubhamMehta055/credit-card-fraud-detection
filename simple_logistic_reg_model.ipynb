{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dbf78b3-2b43-4966-8641-983f98b9550f",
   "metadata": {},
   "source": [
    "# Credit Card fraudulent_Trans Detection Using ML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6da7e93c-58fa-4620-b815-55c8e1153aac",
   "metadata": {},
   "source": [
    "Introduction to the Credit Card fraudulent_Trans Detection Dataset:\n",
    "The Credit Card fraudulent_Trans Detection dataset, available on Kaggle, contains anonymized credit card transactions made by European cardholders in September 2013. The dataset is widely used for building machine learning models aimed at detecting fraudulent_Transulent transactions. It consists of 284,807 transactions, of which 492 (approximately 0.17%) are classified as fraudulent_Transulent, making it a highly imbalanced dataset — a common challenge in fraudulent_Trans detection problems.\n",
    "\n",
    "Due to privacy concerns, most features in the dataset have been transformed using Principal Component Analysis (PCA), and are labeled as V1 to V28. This transformation helps protect sensitive information like transaction amounts and user details. The dataset also includes two other features: \"Time\", which represents the time difference between transactions, and \"Amount\", which reflects the transaction amount.\n",
    "\n",
    "The objective of the project is to classify transactions as fraudulent_Transulent (1) or non-fraudulent_Transulent (0) using this anonymized data, and to address challenges such as class imbalance and feature interpretation. This dataset serves as an excellent resource for practicing anomaly detection and classification techniques in the context of financial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c6e0e-82d7-4d8c-a04f-3f92d8296179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6565541e-d5c7-4b2d-aae4-af2c3aa72e0c",
   "metadata": {},
   "source": [
    "## Importing Main Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc639a75-81b8-4b31-b596-fdb7898ebb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Preprocessing\n",
    "from sklearn.model_selection import train_test_split,cross_val_predict,cross_val_score\n",
    "\n",
    "## Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Metrics\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,roc_auc_score,roc_curve,f1_score\n",
    "from sklearn.metrics import  confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2362ba66-f383-4c38-9046-26bb64863b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1  0.125895 -0.008983  0.014724    2.69    0.0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
       "3 -0.221929  0.062723  0.061458  123.50    0.0  \n",
       "4  0.502292  0.219422  0.215153   69.99    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading The DataSet\n",
    "df=pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ee6789-5b37-4730-8deb-1fa443fe1d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170463, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset informations\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "675f42a5-7453-455b-9fcf-8e5c87f0ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 170463 entries, 0 to 170462\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    170463 non-null  float64\n",
      " 1   V1      170463 non-null  float64\n",
      " 2   V2      170463 non-null  float64\n",
      " 3   V3      170463 non-null  float64\n",
      " 4   V4      170463 non-null  float64\n",
      " 5   V5      170463 non-null  float64\n",
      " 6   V6      170463 non-null  float64\n",
      " 7   V7      170463 non-null  float64\n",
      " 8   V8      170463 non-null  float64\n",
      " 9   V9      170463 non-null  float64\n",
      " 10  V10     170463 non-null  float64\n",
      " 11  V11     170463 non-null  float64\n",
      " 12  V12     170463 non-null  float64\n",
      " 13  V13     170463 non-null  float64\n",
      " 14  V14     170463 non-null  float64\n",
      " 15  V15     170463 non-null  float64\n",
      " 16  V16     170463 non-null  float64\n",
      " 17  V17     170463 non-null  float64\n",
      " 18  V18     170462 non-null  float64\n",
      " 19  V19     170462 non-null  float64\n",
      " 20  V20     170462 non-null  float64\n",
      " 21  V21     170462 non-null  float64\n",
      " 22  V22     170462 non-null  float64\n",
      " 23  V23     170462 non-null  float64\n",
      " 24  V24     170462 non-null  float64\n",
      " 25  V25     170462 non-null  float64\n",
      " 26  V26     170462 non-null  float64\n",
      " 27  V27     170462 non-null  float64\n",
      " 28  V28     170462 non-null  float64\n",
      " 29  Amount  170462 non-null  float64\n",
      " 30  Class   170462 non-null  float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 40.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084d333f-69aa-4ca9-877e-292b26312abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170463.000000</td>\n",
       "      <td>170463.000000</td>\n",
       "      <td>170463.000000</td>\n",
       "      <td>170463.000000</td>\n",
       "      <td>170463.000000</td>\n",
       "      <td>170463.000000</td>\n",
       "      <td>170463.000000</td>\n",
       "      <td>170463.000000</td>\n",
       "      <td>170463.000000</td>\n",
       "      <td>170463.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>170462.000000</td>\n",
       "      <td>170462.000000</td>\n",
       "      <td>170462.000000</td>\n",
       "      <td>170462.000000</td>\n",
       "      <td>170462.000000</td>\n",
       "      <td>170462.000000</td>\n",
       "      <td>170462.000000</td>\n",
       "      <td>170462.000000</td>\n",
       "      <td>170462.000000</td>\n",
       "      <td>170462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60945.692185</td>\n",
       "      <td>-0.171418</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>0.496009</td>\n",
       "      <td>0.118163</td>\n",
       "      <td>-0.177346</td>\n",
       "      <td>0.058682</td>\n",
       "      <td>-0.081195</td>\n",
       "      <td>0.032564</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028654</td>\n",
       "      <td>-0.084279</td>\n",
       "      <td>-0.022592</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>0.092750</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>87.323837</td>\n",
       "      <td>0.002112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27706.565970</td>\n",
       "      <td>1.850499</td>\n",
       "      <td>1.611466</td>\n",
       "      <td>1.382129</td>\n",
       "      <td>1.371813</td>\n",
       "      <td>1.338482</td>\n",
       "      <td>1.295161</td>\n",
       "      <td>1.208874</td>\n",
       "      <td>1.228228</td>\n",
       "      <td>1.152669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743809</td>\n",
       "      <td>0.667001</td>\n",
       "      <td>0.584789</td>\n",
       "      <td>0.598609</td>\n",
       "      <td>0.465168</td>\n",
       "      <td>0.490741</td>\n",
       "      <td>0.392259</td>\n",
       "      <td>0.307549</td>\n",
       "      <td>246.031624</td>\n",
       "      <td>0.045907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-33.680984</td>\n",
       "      <td>-5.519697</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-11.710896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41172.500000</td>\n",
       "      <td>-0.987177</td>\n",
       "      <td>-0.538322</td>\n",
       "      <td>-0.061200</td>\n",
       "      <td>-0.742708</td>\n",
       "      <td>-0.829775</td>\n",
       "      <td>-0.690531</td>\n",
       "      <td>-0.586555</td>\n",
       "      <td>-0.162257</td>\n",
       "      <td>-0.660021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230739</td>\n",
       "      <td>-0.546821</td>\n",
       "      <td>-0.170281</td>\n",
       "      <td>-0.332191</td>\n",
       "      <td>-0.195154</td>\n",
       "      <td>-0.330339</td>\n",
       "      <td>-0.065088</td>\n",
       "      <td>-0.026686</td>\n",
       "      <td>5.470000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60665.000000</td>\n",
       "      <td>-0.185295</td>\n",
       "      <td>0.110233</td>\n",
       "      <td>0.625232</td>\n",
       "      <td>0.124920</td>\n",
       "      <td>-0.227397</td>\n",
       "      <td>-0.202146</td>\n",
       "      <td>-0.032314</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>-0.079157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054634</td>\n",
       "      <td>-0.067189</td>\n",
       "      <td>-0.036388</td>\n",
       "      <td>0.059690</td>\n",
       "      <td>0.136222</td>\n",
       "      <td>-0.059032</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.021198</td>\n",
       "      <td>21.860000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78493.000000</td>\n",
       "      <td>1.183845</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>1.298406</td>\n",
       "      <td>0.938294</td>\n",
       "      <td>0.372807</td>\n",
       "      <td>0.449766</td>\n",
       "      <td>0.462061</td>\n",
       "      <td>0.351272</td>\n",
       "      <td>0.641997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127892</td>\n",
       "      <td>0.362294</td>\n",
       "      <td>0.098484</td>\n",
       "      <td>0.415848</td>\n",
       "      <td>0.399693</td>\n",
       "      <td>0.273055</td>\n",
       "      <td>0.089745</td>\n",
       "      <td>0.078337</td>\n",
       "      <td>76.677500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120194.000000</td>\n",
       "      <td>2.439207</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>19.002942</td>\n",
       "      <td>4.022866</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>12.152401</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>19656.530000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  170463.000000  170463.000000  170463.000000  170463.000000   \n",
       "mean    60945.692185      -0.171418       0.041438       0.496009   \n",
       "std     27706.565970       1.850499       1.611466       1.382129   \n",
       "min         0.000000     -56.407510     -72.715728     -33.680984   \n",
       "25%     41172.500000      -0.987177      -0.538322      -0.061200   \n",
       "50%     60665.000000      -0.185295       0.110233       0.625232   \n",
       "75%     78493.000000       1.183845       0.804500       1.298406   \n",
       "max    120194.000000       2.439207      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  170463.000000  170463.000000  170463.000000  170463.000000   \n",
       "mean        0.118163      -0.177346       0.058682      -0.081195   \n",
       "std         1.371813       1.338482       1.295161       1.208874   \n",
       "min        -5.519697     -42.147898     -26.160506     -43.557242   \n",
       "25%        -0.742708      -0.829775      -0.690531      -0.586555   \n",
       "50%         0.124920      -0.227397      -0.202146      -0.032314   \n",
       "75%         0.938294       0.372807       0.449766       0.462061   \n",
       "max        16.875344      34.801666      22.529298      36.677268   \n",
       "\n",
       "                  V8             V9  ...            V21            V22  \\\n",
       "count  170463.000000  170463.000000  ...  170462.000000  170462.000000   \n",
       "mean        0.032564       0.019095  ...      -0.028654      -0.084279   \n",
       "std         1.228228       1.152669  ...       0.743809       0.667001   \n",
       "min       -73.216718     -13.434066  ...     -34.830382     -10.933144   \n",
       "25%        -0.162257      -0.660021  ...      -0.230739      -0.546821   \n",
       "50%         0.056915      -0.079157  ...      -0.054634      -0.067189   \n",
       "75%         0.351272       0.641997  ...       0.127892       0.362294   \n",
       "max        20.007208      15.594995  ...      27.202839      10.503090   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  170462.000000  170462.000000  170462.000000  170462.000000   \n",
       "mean       -0.022592       0.009210       0.092750       0.012698   \n",
       "std         0.584789       0.598609       0.465168       0.490741   \n",
       "min       -44.807735      -2.836627     -10.295397      -2.604551   \n",
       "25%        -0.170281      -0.332191      -0.195154      -0.330339   \n",
       "50%        -0.036388       0.059690       0.136222      -0.059032   \n",
       "75%         0.098484       0.415848       0.399693       0.273055   \n",
       "max        19.002942       4.022866       7.519589       3.517346   \n",
       "\n",
       "                 V27            V28         Amount          Class  \n",
       "count  170462.000000  170462.000000  170462.000000  170462.000000  \n",
       "mean        0.002063       0.002476      87.323837       0.002112  \n",
       "std         0.392259       0.307549     246.031624       0.045907  \n",
       "min       -22.565679     -11.710896       0.000000       0.000000  \n",
       "25%        -0.065088      -0.026686       5.470000       0.000000  \n",
       "50%         0.008744       0.021198      21.860000       0.000000  \n",
       "75%         0.089745       0.078337      76.677500       0.000000  \n",
       "max        12.152401      33.847808   19656.530000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09ed044-775f-4c88-ace8-7352d42adde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       1\n",
       "V19       1\n",
       "V20       1\n",
       "V21       1\n",
       "V22       1\n",
       "V23       1\n",
       "V24       1\n",
       "V25       1\n",
       "V26       1\n",
       "V27       1\n",
       "V28       1\n",
       "Amount    1\n",
       "Class     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed4d070-baa8-473e-9444-b6af462ebfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0.0    170102\n",
       "1.0       360\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of Legal_Transimate(0) transactions & fraudulent_Transulent(1) transactions\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf87e263-b681-445f-9ee5-96205b74a842",
   "metadata": {},
   "source": [
    "This Dataset is highly unblanced\n",
    "\n",
    "0 --> Normal Transaction\n",
    "\n",
    "1 --> fraudulent_Transulent transaction\n",
    "\n",
    "The first line of code creates a new dataframe called \"Legal_Trans\" by selecting only the rows from the original \"df\" dataframe where the \"Class\" label is equal to 0. In other words, it filters out all transactions labeled as fraudulent_Transulent (Class == 1) and keeps only the Legal_Transimate transactions (Class == 0).\n",
    "\n",
    "The second line of code creates a new dataframe called \"fraudulent_Trans\" by selecting only the rows from the original \"df\" dataframe where the \"Class\" label is equal to 1. This filters out all Legal_Transimate transactions and keeps only the fraudulent_Transulent transactions.\n",
    "\n",
    "By separating the data into two dataframes, it becomes easier to analyze and compare the characteristics of Legal_Transimate and fraudulent_Transulent transactions separately. This can be useful for identifying patterns or features that are more common in fraudulent_Transulent transactions, which can then be used to develop models for fraudulent_Trans detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c21eaa5-6814-4e44-9725-1b6057e4b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Legal_Trans = df[df['Class']==0]\n",
    "fraudulent_Trans = df[df['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f9228e-ff67-4d26-beb8-090ba308cd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170102, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Legal_Trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd243c0-938e-434e-819a-9d1801ff3d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 170102 entries, 0 to 170461\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    170102 non-null  float64\n",
      " 1   V1      170102 non-null  float64\n",
      " 2   V2      170102 non-null  float64\n",
      " 3   V3      170102 non-null  float64\n",
      " 4   V4      170102 non-null  float64\n",
      " 5   V5      170102 non-null  float64\n",
      " 6   V6      170102 non-null  float64\n",
      " 7   V7      170102 non-null  float64\n",
      " 8   V8      170102 non-null  float64\n",
      " 9   V9      170102 non-null  float64\n",
      " 10  V10     170102 non-null  float64\n",
      " 11  V11     170102 non-null  float64\n",
      " 12  V12     170102 non-null  float64\n",
      " 13  V13     170102 non-null  float64\n",
      " 14  V14     170102 non-null  float64\n",
      " 15  V15     170102 non-null  float64\n",
      " 16  V16     170102 non-null  float64\n",
      " 17  V17     170102 non-null  float64\n",
      " 18  V18     170102 non-null  float64\n",
      " 19  V19     170102 non-null  float64\n",
      " 20  V20     170102 non-null  float64\n",
      " 21  V21     170102 non-null  float64\n",
      " 22  V22     170102 non-null  float64\n",
      " 23  V23     170102 non-null  float64\n",
      " 24  V24     170102 non-null  float64\n",
      " 25  V25     170102 non-null  float64\n",
      " 26  V26     170102 non-null  float64\n",
      " 27  V27     170102 non-null  float64\n",
      " 28  V28     170102 non-null  float64\n",
      " 29  Amount  170102 non-null  float64\n",
      " 30  Class   170102 non-null  float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 41.5 MB\n"
     ]
    }
   ],
   "source": [
    "Legal_Trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e09e3ec-533c-4d25-9f4f-f31dd5777f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.000000</td>\n",
       "      <td>170102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60954.436285</td>\n",
       "      <td>-0.159027</td>\n",
       "      <td>0.032193</td>\n",
       "      <td>0.513948</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>-0.168484</td>\n",
       "      <td>0.061850</td>\n",
       "      <td>-0.066521</td>\n",
       "      <td>0.031054</td>\n",
       "      <td>0.025195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030393</td>\n",
       "      <td>-0.084402</td>\n",
       "      <td>-0.022560</td>\n",
       "      <td>0.009386</td>\n",
       "      <td>0.092777</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>87.272509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27700.464110</td>\n",
       "      <td>1.800808</td>\n",
       "      <td>1.586934</td>\n",
       "      <td>1.275396</td>\n",
       "      <td>1.348610</td>\n",
       "      <td>1.299898</td>\n",
       "      <td>1.291401</td>\n",
       "      <td>1.110218</td>\n",
       "      <td>1.174940</td>\n",
       "      <td>1.139335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714809</td>\n",
       "      <td>0.663248</td>\n",
       "      <td>0.579742</td>\n",
       "      <td>0.598814</td>\n",
       "      <td>0.464025</td>\n",
       "      <td>0.490827</td>\n",
       "      <td>0.386213</td>\n",
       "      <td>0.306669</td>\n",
       "      <td>246.067820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-33.680984</td>\n",
       "      <td>-5.519697</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-31.764946</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-6.290730</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-11.710896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41184.250000</td>\n",
       "      <td>-0.983325</td>\n",
       "      <td>-0.539803</td>\n",
       "      <td>-0.055639</td>\n",
       "      <td>-0.744883</td>\n",
       "      <td>-0.826722</td>\n",
       "      <td>-0.688739</td>\n",
       "      <td>-0.583796</td>\n",
       "      <td>-0.162266</td>\n",
       "      <td>-0.656750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230786</td>\n",
       "      <td>-0.546778</td>\n",
       "      <td>-0.170051</td>\n",
       "      <td>-0.332048</td>\n",
       "      <td>-0.195006</td>\n",
       "      <td>-0.330422</td>\n",
       "      <td>-0.065101</td>\n",
       "      <td>-0.026540</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60679.500000</td>\n",
       "      <td>-0.180525</td>\n",
       "      <td>0.108242</td>\n",
       "      <td>0.627623</td>\n",
       "      <td>0.121950</td>\n",
       "      <td>-0.226052</td>\n",
       "      <td>-0.201107</td>\n",
       "      <td>-0.031108</td>\n",
       "      <td>0.056618</td>\n",
       "      <td>-0.077653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055003</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.036307</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.136232</td>\n",
       "      <td>-0.059108</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>0.021165</td>\n",
       "      <td>21.890000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78488.000000</td>\n",
       "      <td>1.184327</td>\n",
       "      <td>0.799852</td>\n",
       "      <td>1.299770</td>\n",
       "      <td>0.932687</td>\n",
       "      <td>0.373315</td>\n",
       "      <td>0.450665</td>\n",
       "      <td>0.462847</td>\n",
       "      <td>0.349979</td>\n",
       "      <td>0.644227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126834</td>\n",
       "      <td>0.361878</td>\n",
       "      <td>0.098302</td>\n",
       "      <td>0.415964</td>\n",
       "      <td>0.399578</td>\n",
       "      <td>0.272779</td>\n",
       "      <td>0.089291</td>\n",
       "      <td>0.078028</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120194.000000</td>\n",
       "      <td>2.439207</td>\n",
       "      <td>18.902453</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>18.709255</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>22.614889</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>19.002942</td>\n",
       "      <td>4.022866</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>12.152401</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>19656.530000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  170102.000000  170102.000000  170102.000000  170102.000000   \n",
       "mean    60954.436285      -0.159027       0.032193       0.513948   \n",
       "std     27700.464110       1.800808       1.586934       1.275396   \n",
       "min         0.000000     -56.407510     -72.715728     -33.680984   \n",
       "25%     41184.250000      -0.983325      -0.539803      -0.055639   \n",
       "50%     60679.500000      -0.180525       0.108242       0.627623   \n",
       "75%     78488.000000       1.184327       0.799852       1.299770   \n",
       "max    120194.000000       2.439207      18.902453       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  170102.000000  170102.000000  170102.000000  170102.000000   \n",
       "mean        0.108071      -0.168484       0.061850      -0.066521   \n",
       "std         1.348610       1.299898       1.291401       1.110218   \n",
       "min        -5.519697     -42.147898     -26.160506     -31.764946   \n",
       "25%        -0.744883      -0.826722      -0.688739      -0.583796   \n",
       "50%         0.121950      -0.226052      -0.201107      -0.031108   \n",
       "75%         0.932687       0.373315       0.450665       0.462847   \n",
       "max        16.875344      34.801666      22.529298      36.677268   \n",
       "\n",
       "                  V8             V9  ...            V21            V22  \\\n",
       "count  170102.000000  170102.000000  ...  170102.000000  170102.000000   \n",
       "mean        0.031054       0.025195  ...      -0.030393      -0.084402   \n",
       "std         1.174940       1.139335  ...       0.714809       0.663248   \n",
       "min       -73.216718      -6.290730  ...     -34.830382     -10.933144   \n",
       "25%        -0.162266      -0.656750  ...      -0.230786      -0.546778   \n",
       "50%         0.056618      -0.077653  ...      -0.055003      -0.067422   \n",
       "75%         0.349979       0.644227  ...       0.126834       0.361878   \n",
       "max        18.709255      15.594995  ...      22.614889      10.503090   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  170102.000000  170102.000000  170102.000000  170102.000000   \n",
       "mean       -0.022560       0.009386       0.092777       0.012642   \n",
       "std         0.579742       0.598814       0.464025       0.490827   \n",
       "min       -44.807735      -2.836627     -10.295397      -2.604551   \n",
       "25%        -0.170051      -0.332048      -0.195006      -0.330422   \n",
       "50%        -0.036307       0.059760       0.136232      -0.059108   \n",
       "75%         0.098302       0.415964       0.399578       0.272779   \n",
       "max        19.002942       4.022866       7.519589       3.517346   \n",
       "\n",
       "                 V27            V28         Amount     Class  \n",
       "count  170102.000000  170102.000000  170102.000000  170102.0  \n",
       "mean        0.001681       0.002371      87.272509       0.0  \n",
       "std         0.386213       0.306669     246.067820       0.0  \n",
       "min       -22.565679     -11.710896       0.000000       0.0  \n",
       "25%        -0.065101      -0.026540       5.490000       0.0  \n",
       "50%         0.008634       0.021165      21.890000       0.0  \n",
       "75%         0.089291       0.078028      76.500000       0.0  \n",
       "max        12.152401      33.847808   19656.530000       0.0  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Legal_Trans.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c4db840-afcb-43ef-ab9a-9f5c903d1af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudulent_Trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52fb9854-5a09-4f9d-82a9-0fb6796b64c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021118952499956"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_percent =len(fraudulent_Trans)/float(len(df))\n",
    "fraud_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e542f2b-ce70-46cc-ab30-0cb2e6288c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Fraud Tnx in datasets : 0.21%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of Fraud Tnx in datasets : {fraud_percent*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d02d7eb9-9332-4cb9-9f0c-ff3492b46ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 360 entries, 541 to 167305\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    360 non-null    float64\n",
      " 1   V1      360 non-null    float64\n",
      " 2   V2      360 non-null    float64\n",
      " 3   V3      360 non-null    float64\n",
      " 4   V4      360 non-null    float64\n",
      " 5   V5      360 non-null    float64\n",
      " 6   V6      360 non-null    float64\n",
      " 7   V7      360 non-null    float64\n",
      " 8   V8      360 non-null    float64\n",
      " 9   V9      360 non-null    float64\n",
      " 10  V10     360 non-null    float64\n",
      " 11  V11     360 non-null    float64\n",
      " 12  V12     360 non-null    float64\n",
      " 13  V13     360 non-null    float64\n",
      " 14  V14     360 non-null    float64\n",
      " 15  V15     360 non-null    float64\n",
      " 16  V16     360 non-null    float64\n",
      " 17  V17     360 non-null    float64\n",
      " 18  V18     360 non-null    float64\n",
      " 19  V19     360 non-null    float64\n",
      " 20  V20     360 non-null    float64\n",
      " 21  V21     360 non-null    float64\n",
      " 22  V22     360 non-null    float64\n",
      " 23  V23     360 non-null    float64\n",
      " 24  V24     360 non-null    float64\n",
      " 25  V25     360 non-null    float64\n",
      " 26  V26     360 non-null    float64\n",
      " 27  V27     360 non-null    float64\n",
      " 28  V28     360 non-null    float64\n",
      " 29  Amount  360 non-null    float64\n",
      " 30  Class   360 non-null    float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 90.0 KB\n"
     ]
    }
   ],
   "source": [
    "fraudulent_Trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fcf1464-83b7-4b6d-8fea-693dde51669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     360.000000\n",
       "mean      111.576722\n",
       "std       227.309252\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%        11.385000\n",
       "75%       104.007500\n",
       "max      1809.680000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudulent_Trans.Amount.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734a872-d93c-48d9-b5f7-fae41a1e45b4",
   "metadata": {},
   "source": [
    "## Handling imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193655c-56b8-4382-98b8-9b1dbd5ea722",
   "metadata": {},
   "source": [
    "## Resampling Technique\n",
    "\n",
    "Oversampling the Minority Class: Increases the instances of the minority class.\n",
    "Techniques include:\n",
    "Random Oversampling: Duplicates samples from the minority class randomly.\n",
    "SMOTE (Synthetic Minority Over-sampling Technique): Generates synthetic samples for the minority class by interpolating between nearby instances.SMOTE looks into minority class instances and use k-neighbor to select \n",
    "a random nearest neighbor ,and a synthetic instance is created randomly in feature space.\n",
    "\n",
    "Undersampling the Majority Class: Reduces instances in the majority class.\n",
    "Techniques include:\n",
    "Random Undersampling: Randomly removes samples from the majority class.\n",
    "Cluster-Based Undersampling: Uses clustering (like k-means) to identify and retain representative samples from the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ceb40-e415-43fa-94a4-93706a1253d9",
   "metadata": {},
   "source": [
    "### Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e1ac555-6239-469d-845f-94647598adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now taking only the no. of Legal_Transimate records which matches with our fraudulent_Trans records(under sample) to make it balanced dataset\n",
    "## This Making The volume Of Two Classes are Equal and Balance The Data\n",
    "legal_sample=Legal_Trans.sample(n=492)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02382d99-7440-42cf-8feb-e0143400f245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54363</th>\n",
       "      <td>46413.0</td>\n",
       "      <td>-1.077384</td>\n",
       "      <td>-1.128529</td>\n",
       "      <td>2.393060</td>\n",
       "      <td>-0.456087</td>\n",
       "      <td>-1.847628</td>\n",
       "      <td>0.531568</td>\n",
       "      <td>0.958805</td>\n",
       "      <td>-0.530225</td>\n",
       "      <td>-0.289653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088316</td>\n",
       "      <td>0.309646</td>\n",
       "      <td>-0.165874</td>\n",
       "      <td>0.442057</td>\n",
       "      <td>0.170422</td>\n",
       "      <td>-0.165868</td>\n",
       "      <td>-0.116570</td>\n",
       "      <td>-0.492978</td>\n",
       "      <td>368.70</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147</th>\n",
       "      <td>15522.0</td>\n",
       "      <td>-0.783984</td>\n",
       "      <td>1.569242</td>\n",
       "      <td>1.412252</td>\n",
       "      <td>1.152618</td>\n",
       "      <td>-0.191701</td>\n",
       "      <td>-0.545313</td>\n",
       "      <td>0.271662</td>\n",
       "      <td>0.302608</td>\n",
       "      <td>0.421591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108174</td>\n",
       "      <td>0.685316</td>\n",
       "      <td>-0.061997</td>\n",
       "      <td>0.580092</td>\n",
       "      <td>-0.192294</td>\n",
       "      <td>-0.306759</td>\n",
       "      <td>0.280471</td>\n",
       "      <td>0.146150</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121076</th>\n",
       "      <td>76062.0</td>\n",
       "      <td>-0.433042</td>\n",
       "      <td>0.903581</td>\n",
       "      <td>1.659245</td>\n",
       "      <td>0.064816</td>\n",
       "      <td>-0.424111</td>\n",
       "      <td>-1.139602</td>\n",
       "      <td>0.557487</td>\n",
       "      <td>0.038157</td>\n",
       "      <td>-0.083597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233122</td>\n",
       "      <td>-0.714673</td>\n",
       "      <td>0.039950</td>\n",
       "      <td>0.632340</td>\n",
       "      <td>-0.313105</td>\n",
       "      <td>0.058412</td>\n",
       "      <td>0.252072</td>\n",
       "      <td>0.119397</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159616</th>\n",
       "      <td>112724.0</td>\n",
       "      <td>1.874604</td>\n",
       "      <td>2.393060</td>\n",
       "      <td>-4.375443</td>\n",
       "      <td>4.732008</td>\n",
       "      <td>2.481984</td>\n",
       "      <td>-1.908574</td>\n",
       "      <td>1.177723</td>\n",
       "      <td>-0.294804</td>\n",
       "      <td>-2.038520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294569</td>\n",
       "      <td>-0.843925</td>\n",
       "      <td>-0.068062</td>\n",
       "      <td>-0.643631</td>\n",
       "      <td>0.225704</td>\n",
       "      <td>0.054471</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>0.102908</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111607</th>\n",
       "      <td>72294.0</td>\n",
       "      <td>-1.802857</td>\n",
       "      <td>0.862908</td>\n",
       "      <td>1.413713</td>\n",
       "      <td>-0.375978</td>\n",
       "      <td>-0.412126</td>\n",
       "      <td>0.300580</td>\n",
       "      <td>0.369527</td>\n",
       "      <td>0.291429</td>\n",
       "      <td>1.061870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205240</td>\n",
       "      <td>0.334731</td>\n",
       "      <td>-0.141434</td>\n",
       "      <td>0.292544</td>\n",
       "      <td>0.160289</td>\n",
       "      <td>0.325066</td>\n",
       "      <td>0.041615</td>\n",
       "      <td>-0.201658</td>\n",
       "      <td>53.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "54363    46413.0 -1.077384 -1.128529  2.393060 -0.456087 -1.847628  0.531568   \n",
       "10147    15522.0 -0.783984  1.569242  1.412252  1.152618 -0.191701 -0.545313   \n",
       "121076   76062.0 -0.433042  0.903581  1.659245  0.064816 -0.424111 -1.139602   \n",
       "159616  112724.0  1.874604  2.393060 -4.375443  4.732008  2.481984 -1.908574   \n",
       "111607   72294.0 -1.802857  0.862908  1.413713 -0.375978 -0.412126  0.300580   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "54363   0.958805 -0.530225 -0.289653  ... -0.088316  0.309646 -0.165874   \n",
       "10147   0.271662  0.302608  0.421591  ...  0.108174  0.685316 -0.061997   \n",
       "121076  0.557487  0.038157 -0.083597  ... -0.233122 -0.714673  0.039950   \n",
       "159616  1.177723 -0.294804 -2.038520  ... -0.294569 -0.843925 -0.068062   \n",
       "111607  0.369527  0.291429  1.061870  ... -0.205240  0.334731 -0.141434   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "54363   0.442057  0.170422 -0.165868 -0.116570 -0.492978  368.70    0.0  \n",
       "10147   0.580092 -0.192294 -0.306759  0.280471  0.146150    5.90    0.0  \n",
       "121076  0.632340 -0.313105  0.058412  0.252072  0.119397    0.89    0.0  \n",
       "159616 -0.643631  0.225704  0.054471  0.009047  0.102908    6.06    0.0  \n",
       "111607  0.292544  0.160289  0.325066  0.041615 -0.201658   53.85    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_df=pd.concat([legal_sample,fraudulent_Trans],axis=0)\n",
    "New_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea9bbf01-20aa-4265-badb-74df97b88c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(852, 31)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8745712-4bfe-4c1a-8a3d-04735b90b5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0.0    492\n",
       "1.0    360\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking The Sampling\n",
    "New_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefec1f5-7603-41d2-9940-a11c3a6c234e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9178b5f4-3e72-49b9-ae99-0771252497c8",
   "metadata": {},
   "source": [
    "## Splitiing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c0aa01e-5e5b-4eb0-88e9-6334250ff1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=New_df.drop('Class',axis=1)\n",
    "y=New_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96d98ec6-c750-4d9f-8ecd-d15578d3be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y) \n",
    "#stratify =y means same no. of values in X_train and y_train and in X_test & y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a860029-fae7-446f-b8f2-6de46c55ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(681, 30) (681,) (171, 30) (171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88136d8b-c288-4685-bdd9-3cf92cb42ce6",
   "metadata": {},
   "source": [
    "Also we can split the train and test data by  Standardization(StandardScaler()) on Amount column and then use the scaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20cc3a-35a6-4d01-bf20-dd66655b8aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63458c22-ce1f-4894-bc7a-5f6f2d2b2689",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd974f-28b5-48b6-9310-5527f1d4a3d9",
   "metadata": {},
   "source": [
    "Hyperparameter C in Logistic Regression :\n",
    "In Logistic Regression, the hyperparameter C controls the regularization strength. It is the inverse of the regularization parameter λ (lambda).\n",
    "\n",
    "C is a hyperparameter controlling regularization in Logistic Regression.\n",
    "\n",
    "A large C weakens regularization (risk of overfitting), while a small C strengthens it (risk of underfitting).\n",
    "\n",
    "C = 0.1 or C = 0.01 means stronger regularization.\n",
    "\n",
    "C = 100 or C = 10 means weaker regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f62572-d1b5-4294-a248-f48d9f26c21c",
   "metadata": {},
   "source": [
    "### Define Hyperparameters for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6286304-6e01-4214-a37f-2566f1e737fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of hyperparameter values for 'C' to test\n",
    "\n",
    "params = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#Tuning C can improve performance metrics like accuracy, precision, recall, or F1-score, depending on the evaluation goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8c9bafe-2f2b-4091-b2e5-146b7200cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=100000)  # max_iter increased for convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a40e38e-a9fa-4984-ba36-ede1a5290c12",
   "metadata": {},
   "source": [
    "### Perform Grid Search for Hyperparameter(C) Tuning\n",
    "We will use GridSearchCV to test all possible values of 'C' and find the best one based on cross-validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcf56658-aea4-48ca-9ae5-898bbbd9af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "log_reg= GridSearchCV(estimator=logreg ,param_grid=params ,scoring='accuracy' ,cv=5)  #performance metric we take accuracy_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b72804-0708-4d58-b9cd-7dc95570c9a6",
   "metadata": {},
   "source": [
    "Choosing cv=5 for cross-validation is a practical choice that balances the trade-offs between having enough folds to provide a reliable estimate of model performance and not overburdening the computational resources. It is widely used and generally provides a good compromise between bias, variance, and computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de8f8f86-9872-4ecd-94a1-80ea7d0eccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subham.mehta\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subham.mehta\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subham.mehta\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subham.mehta\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=100000),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100]}, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=100000),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100]}, scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, max_iter=100000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, max_iter=100000)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=100000),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100]}, scoring='accuracy')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit/train the model to the training data\n",
    "log_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6eae118-1adb-4103-9687-8e848fc8b9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62774e1f-90ed-4663-b057-f501a98c967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9559252898239589"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.best_score_\n",
    "#Example: If log_reg.best_score_ = 0.85, it means the model achieved 85% accuracy during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7ec9101-b285-4ed3-9641-3640a47a3aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhy tune C?\\nImproves Generalization: Proper tuning of C helps the model generalize better to unseen data by finding the right balance between fitting the training data and regularization.\\nOptimizes Performance: Tuning C can improve performance metrics like accuracy, precision, recall, or F1-score, depending on the evaluation goals.\\n\\nSummary:\\nWe didn't tune C in the initial demonstration for simplicity. In practice, hyperparameter tuning using methods like GridSearchCV is essential for optimizing model performance.\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Why tune C?\n",
    "Improves Generalization: Proper tuning of C helps the model generalize better to unseen data by finding the right balance between fitting the training data and regularization.\n",
    "Optimizes Performance: Tuning C can improve performance metrics like accuracy, precision, recall, or F1-score, depending on the evaluation goals.\n",
    "\n",
    "Summary:\n",
    "We didn't tune C in the initial demonstration for simplicity. In practice, hyperparameter tuning using methods like GridSearchCV is essential for optimizing model performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa976c5a-be37-420c-a79a-8e91e4b9f85f",
   "metadata": {},
   "source": [
    "### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9995c5c-20b9-4384-81ec-8ff42e68a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on the test set\n",
    "y_pred=log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1627a9b-2c71-4be0-bdc9-7131b882e925",
   "metadata": {},
   "source": [
    "### Evaluate the model using performance metrics i.e. accuracy, confusion matrix, and classification report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99d77a8e-0f8b-46c5-9ab3-3bb0f96936b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data : 0.95\n",
      "Precision on Test Data : 0.97\n",
      "Recall on Test Data : 0.90\n",
      "ROC_AUC on Test Data : 0.94\n",
      "\n",
      "Confusion Matrix:\n",
      "[[97  2]\n",
      " [ 7 65]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.96        99\n",
      "         1.0       0.97      0.90      0.94        72\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.94      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Evaluate the model using accuracy, confusion matrix, and classification report\n",
    "\n",
    "## accuracy& precision & Recall & ROC_AUC\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_test= precision_score(y_test,y_pred)\n",
    "recall_test= recall_score(y_test,y_pred)\n",
    "roc_auc_test= roc_auc_score(y_test,y_pred)\n",
    "f1_test =f1_score(y_test,y_pred)\n",
    "print(f'Accuracy on Test Data : {accuracy:0.2f}')\n",
    "print(f'Precision on Test Data : {precision_test:0.2f}')\n",
    "print(f'Recall on Test Data : {recall_test:0.2f}')\n",
    "print(f'ROC_AUC on Test Data : {roc_auc_test:0.2f}')\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9cde2b-03fb-45f7-909f-2c18c519be24",
   "metadata": {},
   "source": [
    "So the Max Accuracy  of F1-score is 94% and macro avg is 93% without StandardScaled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9652703-34da-4833-97ef-4b84ab158ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the confusion matrix using heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3725a7d-84d2-41b1-a73d-157b5e0a17f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Fraud', 'Non-Fraud'], yticklabels=['Fraud', 'Non-Fraud'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97ecb7-678a-4365-9461-0533f2370d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a78c2-a0ec-497a-ad50-cf50b9969d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c6b30e-cd9d-4279-a58d-3ccd61f4296c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151ccdd-48c0-4efb-b009-3f46e24dcbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
